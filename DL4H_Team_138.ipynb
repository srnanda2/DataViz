{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srnanda2/DataViz/blob/main/DL4H_Team_138.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project Draft :  Improving clinal outcome predictions using convolution over medical entities with multimodal learning\n",
        "\n",
        "## Team 138 - Soumya Nanda (srnanda2), Ayush Ghosh(ayushg7), Ray Ko (wk021)\n",
        "\n",
        "- Original code link: https://github.com/tanlab/ConvolutionMedicalNer\n",
        "- Team Project code link: https://github.com/ghosh-ayush/DLH_Medical_Convolution\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "j01aH0PR4Sg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "sfk8Zrul_E8V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3890602f-82f8-46a5-ca1e-06bf3d67a53a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "In recent years, the healthcare industry has seen a surge in data generated from electronic health records (EHRs), which provide detailed patient medical histories, treatments, and outcomes. This data presents an unprecedented opportunity for healthcare professionals and researchers to enhance patient care and outcomes through machine learning techniques. By leveraging these methods, such as predicting and diagnosing diseases, customizing treatments, and identifying patients at risk of adverse events.\n",
        "\n",
        "Our project aims to replicate the findings of Bardak and Tan's paper - [2] Improving clinical outcome predictions using convolution over medical entities with multimodal learning.The paper introduces a new approach to predicting two crucial clinical outcomes: patient length of stay (LOS) and mortality. By combining time-series data and clinical notes extracted from EHRs, the authors utilize a gated recurrent unit (GRU) network, named entity recognition (NER), and convolutional neural networks (CNNs). Their method surpasses all tested baseline models, including multimodal architectures."
      ],
      "metadata": {
        "id": "MQ0sNuMePBXx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scope of Reproducibility:\n",
        "\n",
        "The main assertion of the referenced paper, which our study aims to replicate and validate, is that integrating CNN models to extract features from medical entities in clinical notes yields superior results compared to baseline models. This improvement in length of stay (LOS) and mortality metrics suggests that the proposed model could enhance clinical decision-making and patient outcomes.\n",
        "\n",
        "In the paper, time-series data features are generated using a gated recurrent unit (GRU) network, while a pretrained clinical named entity recognition (NER) model identifies seven different medical entities from clinical notes. The NER task categorizes words into predefined groups [3] and assigns labels accordingly. These extracted medical entities are then represented using embeddings and passed through a 1D convolutional neural network (CNN). Finally, the time-series features are combined with medical entity features and processed through a fully connected layer for prediction.\n",
        "In this study, we will replicate this architecture and compare it against several baseline models proposed in the reference paper, including GRU on time-series data, Word2Vec[4], FastText[5], and the combination of both methods on clinical notes.\n",
        "\n",
        "\n",
        "#### Claims from the original paper.\n",
        "The assertion is that incorporating CNN models for feature extraction from medical entities yields higher scores (AUC, AUPRC, and F1) compared to models using time-series data and/or clinical notes. This improvement is observed across four tasks:\n",
        "- In-Hospital mortality prediction\n",
        "- In-ICU mortality prediction\n",
        "- Prediction of Length of ICU stay (LOS) > 3 days\n",
        "- Prediction of LOS exceeding 7 days\n",
        "\n",
        "These tasks are selected because they address common risk prediction scenarios: mortality and length of ICU stay.\n",
        "\n",
        "\n",
        "<b>Both are critical clinical outcomes influencing treatment decisions, resource allocation, and ultimately patient outcomes.</b>\n",
        "\n"
      ],
      "metadata": {
        "id": "uygL9tTPSVHB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Methodology\n",
        "\n",
        "To aid in the reproduction of the results, we forked the code base available from the authors repository '[1](https://github.com/tanlab/ConvolutionMedicalNer)'.\n",
        "\n",
        "\n",
        "A basic '[README](https://github.com/ghosh-ayush/DLH_Medical_Convolution/blob/master/README.md)' file is available within the repository which documents the steps required to run the code. <b>For clarification we encourage the evaluator to kindly look at github repository</b>\n",
        "\n",
        "\n",
        "The code is structured into nine (9) Jupyter Notebooks, each dedicated to a specific task.\n",
        "\n",
        "Notebooks 1-3 handle the data preprocessing steps\n",
        "Notebooks 4-6 focus on creating embeddings and processing time-series data\n",
        "Notebooks 7-9 are utilized to execute both baseline and newly proposed models.\n",
        "Originally, the code was designed for Python 2, but it has since been refactored to be compatible with the more recent Python 3 and TensorFlow 2. Additionally, several bugs were addressed during the refactoring process. The modifications made to each notebook are documented at the top of the respective notebook\n",
        "\n",
        "<b>In this project draft we will be placing the links to the respective notebooks in our GitHub directory and presenting the key results we found so far.\n",
        "\n"
      ],
      "metadata": {
        "id": "xWAHJ_1CdtaA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Data descriptions\n",
        "The data utilized in the paper is sourced from the MIMIC-III database [6, 7], hosted on PhysioNet. Access to PhysioNet is granted upon the completion of required training modules. MIMIC-III is a comprehensive and freely-available database containing de-identified health-related data from over forty thousand patients who were treated in critical care units at the Beth Israel Deaconess Medical Center between 2001 and 2012.\n",
        "\n",
        "The time-series data covers the initial 24 hours following admission to the ICU, with inclusion criteria requiring patients to have at least 30 hours of electronic health record (EHR) data available. We used the below jpynb files in order, Please refer to '[README](https://github.com/ghosh-ayush/DLH_Medical_Convolution/blob/master/README.md)' for more details\n",
        "\n",
        "1. '[Github link](https://github.com/ghosh-ayush/DLH_Medical_Convolution/blob/master/01-Extract-Timeseries-Features.ipynb)'\n",
        "2.  '[Github link](https://github.com/ghosh-ayush/DLH_Medical_Convolution/blob/master/02-Select-SubClinicalNotes.ipynb)'\n",
        "3.  '[Github link](https://github.com/ghosh-ayush/DLH_Medical_Convolution/blob/master/03-Preprocess-Clinical-Notes.ipynb)'\n",
        "\n",
        "Table 1 presents the cohort used for analysis. It's important to note that the values presented in our table differ from those in Table 1 of the original paper.\n",
        "\n",
        "![Table_1.png](https://drive.google.com/uc?export=view&id=1xFta23tpSEoKWZnqdKGEjmJl8O4cgumf)\n",
        "\n",
        "After extracting patients with a minimum of 30 hours of data, the available cohort is larger by seven (7) patients compared to the original paper, with a final cohort size increased by 945 patients.\n"
      ],
      "metadata": {
        "id": "2NbPHUTMbkD3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XzVUQS0CHry0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZScZNbROw-N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34fcaf15-7a5c-44ea-d1ff-6ae027964642"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(18148, 5)\n",
            "First few rows of the smaller version of the Prepocessed data:\n",
            "        SUBJECT_ID  HADM_ID_y           CHARTTIME  \\\n",
            "396836       76021     157169 2135-10-03 12:50:00   \n",
            "531850         870     109361 2127-03-07 06:26:00   \n",
            "607382        8134     112290 2141-08-08 04:01:00   \n",
            "130548       57283     181734 2114-11-24 06:17:00   \n",
            "588002        6957     102224 2178-02-20 17:17:00   \n",
            "\n",
            "                                                     TEXT  \\\n",
            "396836  [**2135-10-3**] 12:50 PM\\n CHEST (PORTABLE AP)...   \n",
            "531850  MICU Nursing Admit Note 0600\\n\\nCode: Full\\nAl...   \n",
            "607382  RESP CARE\\nPT REMAINS [**Name (NI) 136**] AND ...   \n",
            "130548  SICU\\n   HPI:\\n   88F w/ abdominal pain and em...   \n",
            "588002  NPN\\nSee careview for details:\\n\\nNuero: Sedat...   \n",
            "\n",
            "                                        preprocessed_text  \n",
            "396836  [12:50 pm chest ( portable ap ) clip # reason ...  \n",
            "531850  [micu nursing admit note 0600 code : full alle...  \n",
            "607382  [resp care pt remains and vented on a/c 800 x ...  \n",
            "130548  [sicu hpi : 88f w/ abdominal pain and emesis s...  \n",
            "588002  [npn see careview for details : nuero : sedate...  \n"
          ]
        }
      ],
      "source": [
        "# dir and function to load a subset of preprocessed data\n",
        "raw_data_dir = '/content/gdrive/My Drive/Colab Notebooks/small_preprocessed_notes.p'\n",
        "\n",
        "import pandas as pd\n",
        "sub_notes = pd.read_pickle(raw_data_dir)\n",
        "\n",
        "print(sub_notes.shape)\n",
        "print(\"First few rows of the smaller version of the Prepocessed data:\")\n",
        "print(sub_notes.head())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##   Model\n",
        "The proposed multimodal approach employs multiple models to derive its outcomes. In this approach, a Gated Recurrent Unit (GRU) is utilized to extract features from the available time series data.\n",
        "\n",
        "* <b>GRU</b>: A gated recurrent network (GRU) is used to capture the\n",
        "temporal information available within the time series\n",
        "data. A sigmoid classifier is stacked on top of the one\n",
        "layer GRU with 256 hidden units. The use of the GRU\n",
        "on the time series data alone is also one of the baseline\n",
        "models tested. It is also used in conjunction with the\n",
        "other models based on the clinical note data.\n",
        "\n",
        "For the clinical notes, the process involves three main stages:\n",
        "\n",
        "* <b>Extraction of Medical Entities:</b> Med7 is employed to extract medical entities from the notes.\n",
        "The code implements a pre-trained clinical Named Entity Recognition (NER) model known as med7 [10]. Trained on the MIMIC-III dataset, which is also utilized in this project, this pretrained med7 model is employed to extract seven distinct named entities from clinical notes sourced from Electronic Health Records (EHRs). These entities include 'Drug', 'Strength', 'Duration', 'Route', 'Form', 'Dosage', and 'Frequency'. Subsequently, these extracted entities serve as inputs to the designated text embedding models. Given its pretrained nature, the med7 model does not necessitate any parameter tuning.   Please see detailed code implementation in\n",
        "'[Github link](https://github.com/ghosh-ayush/DLH_Medical_Convolution/blob/master/04-Apply-med7-on-Clinical-Notes.ipynb)'\n",
        "\n",
        "* <b>Text Embedding Models</b>: A word embedding model is then applied to generate embeddings from these medical entities.Two different pretrained embedding models were tested:\n",
        "** Word2Vec [11]:\n",
        "A two-layer neural network that learns word representations in two ways: as a continuous bag-of-words and as a skip-gram.\n",
        "** FastText [8]:\n",
        "An extension of Facebook's AI Research (FAIR) labs skip-gram model.\n",
        "Capable of handling out-of-vocabulary words and learning representations for rare words.\n",
        "** Additionally, a third version was tested which concatenated the results from both Word2Vec and FastText embedding models together.\n",
        "No parameter tuning was required for these pretrained models. Please see detailed code implementation in\n",
        "'[Github link](https://github.com/ghosh-ayush/DLH_Medical_Convolution/blob/master/05-Represent-Entities-With-Different-Embeddings.ipynb)' . For detailed implementation codes for getting time series data through GRU models see this '[Github link](https://github.com/ghosh-ayush/DLH_Medical_Convolution/blob/master/06-Create-Timeseries-Data.ipynb)'\n",
        "\n",
        "* <b>Feature Extraction with CNNs:</b> Subsequently, three consecutive 1-layer Convolutional Neural Networks (CNNs) are employed to extract features from the embeddings, followed by passing through a global max pooling layer. The Convolutional Neural Network (CNN) layer consists of three 1D convolutional layers followed by a global max pooling layer. It takes the text embeddings as inputs. The number of parameters for each convolutional layer is calculated using the formula: <i>(kernel size * input dimension + 1) * number of filters </i>. For this model, the input dimension size is 64. The three convolutional layers have 32, 64, and 96 filters, respectively, with a kernel size of 3.\n",
        "\n",
        "* <b> Output Layers </b>: The output layers consist first of a dense (fully connected) layer, which operates on the concatenation of the outputs of the two layers above (output of the CNN and the output of the GRU layer), with dropout regularization\n",
        "applied to the first dense layer. It has an output dimension size of 512 and dropout of 0.2.\n",
        "A second dense layer, with a sigmoid activation function, is finally then used to binary classify the tasks mentioned earlier. The output layer has <i> (output dim +1) ∗ num classes </i> parameters, where the output dimension size is the number of neurons in the previous layer (in this case, 512), and the number of classes is the number of classes in the output (in this case, 1 for binary classification).\n",
        "\n",
        "Finally, the features obtained from both the time series data and the clinical notes are concatenated and passed through a fully connected layer.  "
      ],
      "metadata": {
        "id": "3muyDPFPbozY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and Evaluation\n",
        "\n",
        "* <b>Hyperparameters:</b> Some of the model hyper-parameters used are set to the\n",
        "values described within the original implementation of\n",
        "the paper while others are tuned so as to minimise the\n",
        "binary cross-entropy loss.\n",
        "\n",
        "* <b>Set parameters:</b> A dropout rate of 0.2 is set at the end of the fully connected layer. A ReLU activation function is used for non-linearity and L2 norm for sparsity regularization is selected with the scale factor set to 0.01. For optimization, we use ADAM [9] algorithm with a learning rate\n",
        "of 0.001 and a decay value of 0.01.\n",
        "\n",
        "* <b>Set parameters:</b> The proposed model is trained so as to minimise the\n",
        "binary cross-entropy loss. The following parameters are tuned: number of hidden layers, hidden units, convolutional filters, filter-size, learning rate, dropout rates and regularization parameters on the validation set. Each model is trained for 100 epochs and early stopping is used on the validation loss.\n",
        "\n",
        "\n",
        "\n",
        "We used the author’s code with some modifications and adaptations to make it run using <b>Python 3 and Tensor-Flow </b>. The updated and documented code can be\n",
        "viewed on '[Github](https://github.com/ghosh-ayush/DLH_Medical_Convolution)'. The modifications made to each notebook are documented at the top of each individual\n",
        "notebook.\n"
      ],
      "metadata": {
        "id": "YuRcJn6JMcMk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mittens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "rT7Vb6CQL8Gk",
        "outputId": "1b72e7ba-607e-490f-e39a-d4b9cb6f7b20"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mittens\n",
            "  Downloading mittens-0.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mittens) (1.25.2)\n",
            "Installing collected packages: mittens\n",
            "Successfully installed mittens-0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from gensim.models import Word2Vec, FastText\n",
        "from mittens import GloVe as glove\n",
        "\n",
        "import collections\n",
        "import gc\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.enable_eager_execution()\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout, Input, concatenate, Activation, Concatenate, GRU, Conv2D, MaxPooling2D, UpSampling2D, Conv1D, BatchNormalization, Convolution1D, UpSampling1D, MaxPooling1D, GlobalMaxPooling1D, GlobalAveragePooling1D, MaxPool1D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, History, ReduceLROnPlateau\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.backend import clear_session\n",
        "\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import average_precision_score, roc_auc_score, accuracy_score, f1_score\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "uR7sUHw-LjjG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* <b>Computational requirements: </b>\n",
        "\n",
        "[ AYUSH to FILL HERE ]"
      ],
      "metadata": {
        "id": "0xJa_zsKPv6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# List all available devices\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "cpus = tf.config.list_physical_devices('CPU')\n",
        "\n",
        "if not gpus:\n",
        "    print(\"GPU not available. Training on CPU.\")\n",
        "else:\n",
        "    # Set TensorFlow to only use the first GPU\n",
        "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
        "    print(\"Training on GPU:\", gpus[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "hTtX5_oNMICW",
        "outputId": "b6f0468a-677c-4b5d-830d-c4837ed6cfcf"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU not available. Training on CPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* <b> Running the baseline model which predicts the 4 different clinimal tasks.</b> Please see detailed implementation of the codes in '[Github link](https://github.com/ghosh-ayush/DLH_Medical_Convolution/blob/master/07-TimeseriesBaseline.ipynb)'\n",
        "\n",
        "* We have tried to create a mini version of this implementation using the processed time series data set for the purposes of evaluation. The other models are relativly more complicated and hence we use this step for illustration for 2 epochs and 1 iteration under 8 mins"
      ],
      "metadata": {
        "id": "QhGigq5WRyMf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Write all the pre defined functions here\n",
        "def reset_keras(model):\n",
        "    tf.keras.backend.clear_session()  # Clear the Keras session\n",
        "    del model  # Delete the model to help ensure that the model is garbage collected\n",
        "    gc.collect()  # Suggest to the garbage collector to free up memory\n",
        "\n",
        "    try:\n",
        "        del model # this is from global space - change this as you need\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    gc.collect() # if it's done something you should see a number being outputted\n",
        "\n",
        "def make_prediction_timeseries(model, test_data):\n",
        "    probs = model.predict(test_data)\n",
        "    y_pred = [1 if i>=0.5 else 0 for i in probs]\n",
        "    return probs, y_pred\n",
        "\n",
        "def save_scores_timeseries(predictions, probs, ground_truth, model_name,\n",
        "                problem_type, iteration, hidden_unit_size, type_of_ner):\n",
        "\n",
        "    auc = roc_auc_score(ground_truth, probs)\n",
        "    auprc = average_precision_score(ground_truth, probs)\n",
        "    acc   = accuracy_score(ground_truth, predictions)\n",
        "    F1    = f1_score(ground_truth, predictions)\n",
        "\n",
        "\n",
        "    result_dict = {}\n",
        "    result_dict['auc'] = auc\n",
        "    result_dict['auprc'] = auprc\n",
        "    result_dict['acc'] = acc\n",
        "    result_dict['F1'] = F1\n",
        "\n",
        "\n",
        "    file_name = str(hidden_unit_size)+\"-\"+model_name+\"-\"+problem_type+\"-\"+str(iteration)+\"-\"+type_of_ner+\".p\"\n",
        "\n",
        "    result_path = \"/content/gdrive/My Drive/Colab Notebooks/Results\"\n",
        "    pd.to_pickle(result_dict, os.path.join(result_path, file_name))\n",
        "\n",
        "    print(\"auc:\", auc, \", auprc:\", auprc, \", acc:\", acc, \", F1:\", F1)\n",
        "\n",
        "def timeseries_model(layer_name, number_of_unit):\n",
        "    clear_session()\n",
        "\n",
        "    sequence_input = Input(shape=(24,104),  name = \"timeseries_input\")\n",
        "\n",
        "    x = GRU(number_of_unit)(sequence_input)\n",
        "\n",
        "    logits_regularizer = tf.keras.regularizers.l2(0.01)\n",
        "    sigmoid_pred = Dense(1, activation='sigmoid',use_bias=False,\n",
        "                         kernel_initializer=tf.keras.initializers.GlorotUniform(),\n",
        "                  kernel_regularizer=logits_regularizer)(x)\n",
        "\n",
        "\n",
        "    model = Model(inputs=sequence_input, outputs=sigmoid_pred)\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "    return model\n",
        "#LOAD THE TRAINING,VALIDATION AND TEST DATA SETS\n",
        "type_of_ner='new'\n",
        "x_train = pd.read_pickle(\"/content/gdrive/My Drive/Colab Notebooks/Data/new_x_train.pkl\")\n",
        "x_dev   = pd.read_pickle(\"/content/gdrive/My Drive/Colab Notebooks/Data/new_x_dev.pkl\")\n",
        "x_test  = pd.read_pickle(\"/content/gdrive/My Drive/Colab Notebooks/Data/new_x_test.pkl\")\n",
        "\n",
        "y_train = pd.read_pickle(\"/content/gdrive/My Drive/Colab Notebooks/Data/new_y_train.pkl\")\n",
        "y_dev   = pd.read_pickle(\"/content/gdrive/My Drive/Colab Notebooks/Data/new_y_dev.pkl\")\n",
        "y_test  = pd.read_pickle(\"/content/gdrive/My Drive/Colab Notebooks/Data/new_y_test.pkl\")\n",
        "\n",
        "#RUN THE TRAINING WITH 2 EPOCHS FOR THE PURPOSES of EVALUATION\n",
        "epoch_num        = 2 #we are amending the epochs\n",
        "model_patience   = 3\n",
        "monitor_criteria = 'val_loss'\n",
        "batch_size       = 128\n",
        "\n",
        "unit_sizes       = [256]\n",
        "iter_num         = 2 # we are amending the number of iterations to 1 just for illustration\n",
        "target_problems  = ['mort_hosp', 'mort_icu', 'los_3', 'los_7']\n",
        "layers           = [\"GRU\"]\n",
        "\n",
        "for each_layer in layers:\n",
        "    for each_unit_size in unit_sizes:\n",
        "        for iteration in range(1, iter_num):\n",
        "            for each_problem in target_problems:\n",
        "\n",
        "                print(\"Layer: \", each_layer)\n",
        "                print(\"Hidden unit: \", each_unit_size)\n",
        "                print (\"Problem type: \", each_problem)\n",
        "                print(\"Iteration number: \", iteration)\n",
        "                print (\"__________________\")\n",
        "\n",
        "\n",
        "                early_stopping_monitor = EarlyStopping(monitor=monitor_criteria, patience=model_patience)\n",
        "\n",
        "                #best_model_name = str(each_layer)+\"-\"+str(each_unit_size)+\"-\"+str(each_problem)+\"-\"+\"best_model.hdf5\"\n",
        "                best_model_name = str(each_layer) + \"-\" + str(each_unit_size) + \"-\" + str(each_problem) + \"-\" + \"best_model.keras\"\n",
        "\n",
        "                checkpoint = ModelCheckpoint(best_model_name,\n",
        "                                             monitor='val_loss',\n",
        "                                             verbose=0,\n",
        "                                             save_best_only=True,\n",
        "                                             mode='min',\n",
        "                                             #period=1\n",
        "                                            )\n",
        "\n",
        "                callbacks = [early_stopping_monitor, checkpoint]\n",
        "\n",
        "                model = timeseries_model(each_layer, each_unit_size)\n",
        "                model.fit(x_train,\n",
        "                          y_train[each_problem],\n",
        "                          epochs=epoch_num,\n",
        "                          verbose=0,\n",
        "                          validation_data=(x_dev, y_dev[each_problem]),\n",
        "                          callbacks=callbacks,\n",
        "                          batch_size= batch_size)\n",
        "\n",
        "                model.load_weights(best_model_name)\n",
        "\n",
        "                probs, predictions = make_prediction_timeseries(model, x_test)\n",
        "                save_scores_timeseries(predictions, probs, y_test[each_problem].values,str(each_layer),\n",
        "                                       each_problem, iteration, each_unit_size,type_of_ner)\n",
        "                reset_keras(model)\n",
        "                clear_session()\n",
        "                gc.collect()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "iU3c7h6hXYg5",
        "outputId": "28f5440d-5b62-47cc-e966-77eeaeec2422"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer:  GRU\n",
            "Hidden unit:  256\n",
            "Problem type:  mort_hosp\n",
            "Iteration number:  1\n",
            "__________________\n",
            "138/138 [==============================] - 4s 25ms/step\n",
            "auc: 0.8770703755556065 , auprc: 0.5562853684378408 , acc: 0.9132711131345322 , F1: 0.39427662957074716\n",
            "Layer:  GRU\n",
            "Hidden unit:  256\n",
            "Problem type:  mort_icu\n",
            "Iteration number:  1\n",
            "__________________\n",
            "138/138 [==============================] - 4s 26ms/step\n",
            "auc: 0.8873756056733026 , auprc: 0.4670652481400007 , acc: 0.9358069656271341 , F1: 0.3788546255506608\n",
            "Layer:  GRU\n",
            "Hidden unit:  256\n",
            "Problem type:  los_3\n",
            "Iteration number:  1\n",
            "__________________\n",
            "138/138 [==============================] - 6s 42ms/step\n",
            "auc: 0.6895790327259023 , auprc: 0.622007404261435 , acc: 0.6562713407694059 , F1: 0.5545722713864307\n",
            "Layer:  GRU\n",
            "Hidden unit:  256\n",
            "Problem type:  los_7\n",
            "Iteration number:  1\n",
            "__________________\n",
            "138/138 [==============================] - 3s 20ms/step\n",
            "auc: 0.7214657093339937 , auprc: 0.19683184045311303 , acc: 0.919872524470749 , F1: 0.043478260869565216\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Futhermore we run the multimodal base line model that uses the word representations obtained while applying the embedding. Please see '[Github link](https://github.com/ghosh-ayush/DLH_Medical_Convolution/blob/master/08-Multimodal-Baseline.ipynb)'\n",
        "\n",
        "* Finally we run proposed model from the original paper, which uses 1D convolutional layers as a feature extractor on medical entities obtained through the embedding techniques, train and evaluate its performance on the 4 tasks. Please see  '[Github link](https://github.com/ghosh-ayush/DLH_Medical_Convolution/blob/master/09-Proposed-Model.ipynb)'"
      ],
      "metadata": {
        "id": "uLV_AnQbf7a0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results\n",
        "\n",
        "### Comparing results from baseline model replication\n",
        "Please use '[Github link](https://github.com/ghosh-ayush/DLH_Medical_Convolution/blob/master/load_print_results.ipynb)' for this section to get details of the runs that we acheived\n",
        "\n",
        "\n",
        "In order to assess the validity of the four claims outlined in the section <b> Claims from the paper</b>, we initially computed the mean AUC, AUPRC, and F1 score for the baseline models. Four baseline models were executed: the GRU model utilizing solely time-series data, and three average multimodal models - \"Word2Vec\", \"FastText\", and the concatenation of these two embedding techniques with the GRU output. Each model underwent ten (10) runs, and the average results were recorded. Table below illustrates the performance comparison of these baseline models, mirroring the presentation in the original paper.\n",
        "\n",
        "<b>Results from our replication for baseline models</b>\n",
        "![Baseline](https://drive.google.com/uc?export=view&id=1sxVf0NtjZnpO0LGnELAUS5tWrHut1XQI)\n",
        "\n",
        "<b>Original Results for baseline models</b>\n",
        "![Baseline_Original](https://drive.google.com/uc?export=view&id=18kgVa9MGqkwDuImQxApjvIUIXNVIP7QF)\n",
        "\n",
        "As a comparsion to what we see in the paper vs. our generation, we could not match the results exactly. However, they can be broadly similay when it comes to using average multimodal elements. Please note that we managed to run the evarge multimodel embeddings to be compared to GRU but see differences in results.\n",
        "* One thing to notice is GRU is better in F1 scores for LOS > 3 days and LOS > 7 days predictions than the multimodel average embeddings\n",
        "\n",
        "### Comparing results from proposed model replication\n",
        "\n",
        "<b>Results from our replication for proposed models</b>\n",
        "![Proposed](https://drive.google.com/uc?export=view&id=1t2gxlyt3TVDxQ5appNXGYM5-dHyaa4Tu)\n",
        "\n",
        "<b>Original Results for proposed models</b>\n",
        "![Proposed_Original](https://drive.google.com/uc?export=view&id=1Y3HeH7jsEsxo9XUxgmxxN7vNCMDc1vRk)\n",
        "\n",
        "\n",
        "Again our results were not exactly replicable with the output from the paper. Best baseline model seems to be performing better in most of the cases as compared to the proposed models. Furthermore, we dont see the proposed model outperforming the Baseline model consistently as compared to the bestline model which is claimed by the paper\n"
      ],
      "metadata": {
        "id": "gX6bCcZNuxmz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model comparison\n",
        "\n",
        "#### In-Hospital Mortality\n",
        "In the original paper, the use of ”Word2Vec” embedding model in the proposed model architecture provided the highest scores across all AUC, AUPRC and F1 metrics.\n",
        "However, in our reproduced results, we have found that the best baseline model outperforms all the proposed model metrics as per the results table in the previous section\n",
        "\n",
        "#### In-ICU Mortality\n",
        "\n",
        "Originally the proposed model with ”Word2Vec” embeddings provided the top results for AUC and AUPRC with ”FastText” providing the top for F1. However,\n",
        "similar to the in-hospital mortality task, the reproduced results show the baseline models again outperform for AUC and AUPRC\n",
        "\n",
        "#### LOS > 3\n",
        "\n",
        "The task of determining length of ICU stay greater than 3 days is the only task in which the reproduced results show the proposed model outperforming the baseline model in two out of the three metrics, namely AUC and AUPRC. In this case, the ”Word2Vec” embedding technique is shown to have the best results. However, in the original paper, it was the ”Concat” model which showed\n",
        "best results for AUC and AUPRC and the ”FastText” model which was optimal for F1 metric.\n",
        "\n",
        "#### LOS >7\n",
        "\n",
        "the task of determining length of ICU stay greater than seven days, the results show again that the baseline model outperforms the best results from the\n",
        "proposed models across 2 scoring metrics.\n",
        "\n",
        "Overall we could not replicate the results as per the proposed paper\n",
        "\n"
      ],
      "metadata": {
        "id": "8EAWAy_LwHlV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discussion\n",
        "\n",
        "\n",
        "Our reproduction's results diverge from those of the original paper despite utilizing the same dataset and the authors' code. The baseline model surpassed the proposed models in 10 out of 12 evaluation metrics across various tasks. Surprisingly, not only did the proposed model fail to match the original results, but nearly every result we obtained exceeded those reported in the paper. The mean discrepancy observed among the trained models is detailed in the Results section. The diminished performance of the proposed models can be attributed to the enhanced performance of the baseline models compared to the proposed ones.\n",
        "\n",
        "The discrepancies between our reproduction and the original paper likely stem from differences in the analysis cohort size (22,025 versus 21,080 patients) between the two implementations. This discrepancy was attributed to two issues. Firstly, variations in the code versions used to extract test data from the MIMIC-III dataset resulted in minor differences in the number of subjects used. This issue was tested and verified. Secondly, differences in versions of the med7 model were hypothesized to contribute to the discrepancy, although this could not be confirmed. Our findings suggest that while the results presented in the original paper may have been accurate at the time, updates and improvements to the models utilized in this analysis have minimized the impact of incorporating the proposed CNN layer into the model architecture.\n",
        "\n",
        "\n",
        "Several factors contributed to the successful replication of the selected paper. These factors included:\n",
        "\n",
        "* The accessibility of the code in a GitHub repository ensured that we executed identical code and constructed models consistent with those of the original authors.\n",
        "* The presentation of findings in tables within the original paper facilitated straightforward comparison between our results and theirs.\n",
        "* The dataset was relatively small in size, enabling us to store it locally without the need for external storage services.\n",
        "\n",
        "\n",
        "Despite the mentioned advantages, we faced several hurdles during our replication efforts. These challenges included:\n",
        "\n",
        "* The code provided in the paper was written using outdated dependencies, resulting in deprecated functions and variables. As a result, we had to identify and replace these deprecated components with equivalents from the latest dependency versions.\n",
        "* The original code lacked adequate comments or documentation, making it challenging to understand and follow.\n",
        "* While the paper did not specify a requirement for a GPU, the computations were resource-intensive, often requiring overnight runs. However, we encountered errors after a few hours, leading to delays.\n",
        "* Ensuring accuracy and adherence to the paper proved challenging due to discrepancies with the original results. Speculating on the reasons behind these inconsistencies was also difficult.\n",
        "\n",
        "To facilitate the reproduction of results, we suggest that the original authors implement the following recommendations:\n",
        "\n",
        "\n",
        "* <b>Set a random seed value</b> to ensure that the results are reproducible, even when the code is run multiple times.\n",
        "\n",
        "* <b>Update for Compatibility:</b> The code has been updated to ensure compatibility with the latest versions of Python and TensorFlow, ensuring smooth operation with the most recent software releases.\n",
        "\n",
        "* <b>Model Version Documentation:</b> Detailed documentation of the versions of all models used, including MIMIC Extract and med7, enables easy replication of experiments by providing the necessary model versions.\n",
        "\n",
        "* <b>Enhanced Documentation with Comments:</b> The code's documentation has been enriched with explanatory comments, making it easier to understand the functionality and workflow of the code.\n",
        "\n",
        "\n",
        "<b>We have shared our github repository if they would find it helpful for implementing the above suggestions</b>\n",
        "\n",
        "\n",
        "# Further to dos\n",
        "* We will be reaching out to the authors to understand the discrepencies further\n",
        "* We would be further spending time to check our results vs that of the paper to pin down on any particular reason\n",
        "* We will work on adding a couple of ablations if possible\n",
        "* Some more visualisation in the results section"
      ],
      "metadata": {
        "id": "qH75TNU71eRH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "\n",
        "1.  B. Bardak and Tan M. Convolutionmedicalner. https://github.com/tanlab/ConvolutionMedicalNer, 2020.\n",
        "2. Batuhan Bardak and Mehmet Tan. Improving clinical outcome predictions using convolution over medical entities with multimodal learning, 2020.\n",
        "3. Hinrich Sch¨utze Christopher D. Manning, Prabhakar Raghavan. Introduction to Information Retrieval. Cambridge University Press, 2008. ISBN:0521865719.\n",
        "4. A. L. Goldberger, L. A. N. Amaral, L. Glass, J. M. Hausdorff, P. Ch. Ivanov, R. G. Mark, J. E. Mietus, G. B. Moody, C.-K. Peng, and H. E.Stanley. PhysioBank, PhysioToolkit, and PhysioNet: Components of a new research resource for complex physiologic signals. Circulation, 101(23):e215–e220,2000 (June 13). Circulation Electronic Pages:http://circ.ahajournals.org/content/101/23/e215.full PMID:1085218; doi: 10.1161/01.CIR.101.23.e215.\n",
        "5. Kexin Huang, Jaan Altosaar, and Rajesh Ranganath. Clinicalbert: Modeling clinical notes and predicting hospital readmission, 2020.\n",
        "6. Alistair E. W. Johnson, Tom J. Pollard, and Roger G.Mark. Mimic-iii clinical database (version 1.4). PhysioNet,2016.\n",
        "7. Alistair E. W. Johnson, Tom J. Pollard, Lu Shen, Liwei H. Lehman, Mengling Feng, Mohammad Ghassemi, Benjamin Moody, Peter Szolovits, Leo Anthony\n",
        "Celi, and Roger G. Mark. Mimic-iii, a freely accessible critical care database. Scientific Data, 3(1):160035, 2016.\n",
        "8. Armand Joulin, Edouard Grave, Piotr Bojanowski, and Tomas Mikolov. Bag of tricks for efficient text classification, 2016.\n",
        "9. Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization, 2017.\n",
        "10. Andrey Kormilitzin, Nemanja Vaci, Qiang Liu, and Alejo Nevado-Holgado. Med7: A transferable clinical natural language processing model for electronic\n",
        "health records. Artificial Intelligence in Medicine, 118:102086, 2021.\n",
        "11. Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey\n",
        " Dean. Efficient estimation of word representations in vector space, 2013.\n"
      ],
      "metadata": {
        "id": "SHMI2chl9omn"
      }
    }
  ]
}